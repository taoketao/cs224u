{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bake-off: The semantic orientation method\n",
    "\n",
    "__Important__: This isn't being run as a bake-off this year. It's included in the repository in case people want to do additional exploration or incorporate this kind of evaluation into a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Morgan Bryant orig. Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = 'vsmdata'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_orientation(\n",
    "        df,        \n",
    "        seeds1=default_seeds1,\n",
    "        seeds2=default_seeds2,\n",
    "        distfunc=vsm.cosine):    \n",
    "    \"\"\"No frills implementation of the semantic Orientation (SO) method of \n",
    "    Turney and Littman. `seeds1` and `seeds2` should be representative members \n",
    "    of two intutively opposing semantic classes. The method will then try \n",
    "    to rank the vocabulary by its relative association with each seed set.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The matrix used to derive the SO ranking.           \n",
    "    seeds1 : tuple of str\n",
    "        The default is the negative seed set of Turney and Littman.        \n",
    "    seeds2 : tuple of str\n",
    "        The default is the positive seed set of Turney and Littman.        \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure \n",
    "        between 1d vectors. \n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    pd.Series\n",
    "        The vocabulary ranked according to the SO method, with words \n",
    "        closest to `seeds1` at the top and words closest to `seeds2` at the \n",
    "        bottom.\n",
    "    \n",
    "    \"\"\"\n",
    "    rownames = set(df.index)\n",
    "    # Check that the seed sets are in the vocabulary, filtering\n",
    "    # where necessary, and warn the user about exclusions:\n",
    "    seeds1 = _value_check(seeds1, \"seeds1\", rownames)\n",
    "    seeds2 = _value_check(seeds2, \"seeds2\", rownames)\n",
    "    \n",
    "    # Subframes for the two seeds-sets\n",
    "    sm1 = df.loc[seeds1]\n",
    "    sm2 = df.loc[seeds2]\n",
    "    \n",
    "    # Core semantic orientation calculation:\n",
    "    def row_func(row):\n",
    "        val1 = sm1.apply(lambda x: distfunc(row, x), axis=1).sum()\n",
    "        val2 = sm2.apply(lambda x: distfunc(row, x), axis=1).sum()\n",
    "        return val1 - val2\n",
    "    \n",
    "    scores = df.apply(row_func, axis=1)\n",
    "    return scores.sort_values(ascending=False)\n",
    "\n",
    "def _value_check(ss, name, rownames):\n",
    "    new = set()\n",
    "    for w in ss:\n",
    "        if w not in rownames:\n",
    "            print(\"Warning: {} not in {}\".format(w, name))\n",
    "        else:\n",
    "            new.add(w)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb20 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window20-flat.csv.gz'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb20_ppmi = vsm.pmi(imdb20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inferior not in seeds1\n"
     ]
    }
   ],
   "source": [
    "imdb20_ppmi_so = semantic_orientation(imdb20_ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    0.596622\n",
       "superb       0.249968\n",
       "great        0.247541\n",
       "superior     0.230842\n",
       "nice         0.189436\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb20_ppmi_so.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unfortunate   -1.694198\n",
       "nasty         -1.838113\n",
       "poor          -1.907216\n",
       "wrong         -1.929000\n",
       "bad           -1.954924\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb20_ppmi_so.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional sentiment lexicon\n",
    "\n",
    "[Warriner et al. (20130](http://www.humanities.mcmaster.ca/~vickup/Warriner-etal-BRM-2013.pdf) released a dataset called 'Norms of valence, arousal, and dominance for 13,915 English lemmas'. This is included in `vsmdata` as `Ratings_Warriner_et_al.csv`. The following code reads this file in and creates a DataFrame that gives just the overall means for these three semantic dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_warriner_lexicon(src_filename, df=None):\n",
    "    \"\"\"Read in 'Ratings_Warriner_et_al.csv' and optionally restrict its \n",
    "    vocabulary to items in `df`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to 'Ratings_Warriner_et_al.csv'\n",
    "    df : pd.DataFrame or None\n",
    "        If this is given, then its index is intersected with the \n",
    "        vocabulary from the lexicon, and we return a lexicon \n",
    "        containing only values in both vocabularies.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    lexicon = pd.read_csv(src_filename, index_col=0)\n",
    "    lexicon = lexicon[['Word', 'V.Mean.Sum', 'A.Mean.Sum', 'D.Mean.Sum']]\n",
    "    lexicon = lexicon.set_index('Word').rename(\n",
    "        columns={'V.Mean.Sum': 'Valence', \n",
    "                 'A.Mean.Sum': 'Arousal', \n",
    "                 'D.Mean.Sum': 'Dominance'})\n",
    "    if df is not None:\n",
    "        shared_vocab = sorted(set(lexicon.index) & set(df.index))\n",
    "        lexicon = lexicon.loc[shared_vocab]\n",
    "    return lexicon\n",
    "\n",
    "def evaluation(lexicon, so, colname='Valence', metric=pearsonr):\n",
    "    lexicon['so'] = so\n",
    "    rho, pvalue = metric(lexicon['so'], lexicon[colname])\n",
    "    print(\"{0:}'s r: {1:0.3f}\".format(metric.__name__, rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load data '''\n",
    "this_dir = os.getcwd()\n",
    "data_home = 'vsmdata'\n",
    "imdb20 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window20-flat.csv.gz'), index_col=0)\n",
    "imdb5 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window5-scaled.csv.gz'), index_col=0)\n",
    "print(imdb20.shape, imdb5.shape)\n",
    "# gigaword 5\n",
    "# gigaword 20\n",
    "\n",
    "lexicon = load_warriner_lexicon(\n",
    "    os.path.join(data_home, 'Ratings_Warriner_et_al.csv'),\n",
    "    imdb20) # imdb20 has same shape as imdb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>5.42</td>\n",
       "      <td>4.29</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4.85</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>6.64</td>\n",
       "      <td>3.38</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abortion</th>\n",
       "      <td>2.58</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolute</th>\n",
       "      <td>5.43</td>\n",
       "      <td>3.48</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Valence  Arousal  Dominance\n",
       "Word                                 \n",
       "TV           5.42     4.29       6.23\n",
       "ability      7.00     4.85       6.55\n",
       "able         6.64     3.38       6.17\n",
       "abortion     2.58     5.43       4.73\n",
       "absolute     5.43     3.48       5.58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ABC.apply(vsm.length_norm, axis=1)\n",
    "imdb20_tmp = imdb20.copy()\n",
    "imdb20_tmp.apply(vsm.length_norm, axis=1)\n",
    "\n",
    "#imdb20_tmp.apply(vsm.length_norm, axis=0)\n",
    "#print(imdb20_tmp.mean().tail(), imdb20.mean().tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb20_n0 = imdb20.apply(vsm.length_norm, axis=1)\n",
    "imdb20_n01 = imdb20_n0.apply(vsm.length_norm, axis=0)\n",
    "imdb20_n01_ppmi = vsm.pmi(imdb20_n01)\n",
    "imdb20_n01_ppmi = imdb20_n01_ppmi.apply(vsm.length_norm, axis=1)\n",
    "imdb20_n01_ppmi = imdb20_n01_ppmi.apply(vsm.length_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig set: (('bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior'),)\n",
      "orig ssd: defaultdict(<function bootstrap.<locals>.<lambda> at 0x130110510>, {'bad': 1.0, 'nasty': 1.0, 'poor': 1.0, 'negative': 1.0, 'unfortunate': 1.0, 'wrong': 1.0, 'inferior': 1.0})\n",
      "depth 0 on ['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior'] :\n",
      "current set size: p 0 25\n",
      "depth 1 on ['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior', 'textile', 'worm', 'unpleasant', \"what's\", \"don't\", 'terribly', 'reviews', 'comments', 'positive', 'bratislava', 'excuse', 'liechtenstein', 'scouting', 'events', 'fortunate', 'guys', 'carnivore', 'seed'] :\n",
      "current set size: p 1 69\n",
      "depth 2 on ['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior', 'textile', 'worm', 'unpleasant', \"what's\", \"don't\", 'terribly', 'reviews', 'comments', 'positive', 'bratislava', 'excuse', 'liechtenstein', 'scouting', 'events', 'fortunate', 'guys', 'carnivore', 'seed', 'hole', 'pug', 'giant', 'slovakia', 'warsaw', 'boyfriend', 'simon', 'italian', 'whilst', 'melons', 'talent', 'mammal', 'awesome', 'reptiles', 'dated', 'disappointed', 'boring', 'enough', 'catch', 'screening', 'thoroughly', 'disgusting', 'depressing', 'actual', 'mogadishu', 'based', 'mill', 'fabric', 'garment', 'happening', 'cooking', 'sunflower', 'dandelion', 'onions', 'posted', 'feedback', 'hey', 'dolls', 'milwaukee', 'bother', 'know', 'normally', 'pathetic', 'sorry'] :\n",
      "current set size: p 2 163\n",
      "orig set: (('good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior'),)\n",
      "orig ssd: defaultdict(<function bootstrap.<locals>.<lambda> at 0x130110488>, {'good': 1.0, 'nice': 1.0, 'excellent': 1.0, 'positive': 1.0, 'fortunate': 1.0, 'correct': 1.0, 'superior': 1.0})\n",
      "depth 0 on ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior'] :\n",
      "current set size: n 0 28\n",
      "depth 1 on ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior', 'grief', '*****', 'pretty', 'error', 'simplest', 'miniature', 'far', 'intellect', 'doodle', 'hanoi', 'an', 'lithuania', 'touches', 'diversion', 'touch', 'negative', 'reviews', 'feedback', 'enough', 'catch', 'screening'] :\n",
      "current set size: n 1 76\n",
      "depth 2 on ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior', 'grief', '*****', 'pretty', 'error', 'simplest', 'miniature', 'far', 'intellect', 'doodle', 'hanoi', 'an', 'lithuania', 'touches', 'diversion', 'touch', 'negative', 'reviews', 'feedback', 'enough', 'catch', 'screening', 'lucky', '****', '***', 'SPOILER', 'flute', 'mouse', 'rock', 'comments', 'pain', 'loss', 'guilt', 'terms', 'plots', 'query', 'managed', 'acrylic', 'ipod', 'frost', 'vilnius', 'latvia', 'estonia', 'jane', 'folks', 'compound', 'parrot', 'challenge', 'wit', 'chord', 'heart', 'soul', 'terrier', 'golf', 'poodle', 'inconvenient', 'invoice', 'origami', 'damn', 'decent', 'festival', 'press', 'concerned', 'galaxy', 'printer', 'ministry', 'ways', 'pleasant', 'afternoon', 'amusing'] :\n",
      "current set size: n 2 176\n"
     ]
    }
   ],
   "source": [
    "''' Morgan Bryant: this is a small bootstrapping algorithm\n",
    "that seeks to expand the given default seeds (considered \n",
    "\"paragons\") by operating on a differentially modified dataset.'''\n",
    "\n",
    "import bakeoff_semantic_orientation as bso\n",
    "importlib.reload(bso)\n",
    "\n",
    "# Operate on the seed sets\n",
    "laplace = 1.0\n",
    "nsteps = 3\n",
    "nadditions = 4\n",
    "def dist_factor(step):\n",
    "    return 1.0\n",
    "    #return 1+nsteps-step\n",
    "\n",
    "#DF = imdb20_n01_ppmi\n",
    "df = vsm.pmi(imdb5)\n",
    "ss1_counts, ss1 = bso.bootstrap(default_seeds1, df, 'p', \n",
    "                      dist_factor, laplace, nsteps, nadditions)\n",
    "ss2_counts, ss2 = bso.bootstrap(default_seeds2, df, 'n',\n",
    "                      dist_factor, laplace, nsteps, nadditions)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior', 'textile', 'worm', 'unpleasant', \"what's\", \"don't\", 'terribly', 'reviews', 'comments', 'positive', 'bratislava', 'excuse', 'liechtenstein', 'scouting', 'events', 'fortunate', 'guys', 'carnivore', 'seed', 'hole', 'pug', 'giant', 'slovakia', 'warsaw', 'boyfriend', 'simon', 'italian', 'whilst', 'melons', 'talent', 'mammal', 'awesome', 'reptiles', 'dated', 'disappointed', 'boring', 'enough', 'catch', 'screening', 'thoroughly', 'disgusting', 'depressing', 'actual', 'mogadishu', 'based', 'mill', 'fabric', 'garment', 'happening', 'cooking', 'sunflower', 'dandelion', 'onions', 'posted', 'feedback', 'hey', 'dolls', 'milwaukee', 'bother', 'know', 'normally', 'pathetic', 'sorry', 'pears', 'melon', 'pineapples', 'lucky', 'laredo', 'belgrade', \"didn't\", 'expect', 'plano', 'footage', 'run', 'steel', 'pigeon', 'rabbit', 'enjoyed', 'enjoyable', 'entertained', 'petals', 'favourite', 'salad', 'girlfriend', 'her', 'insects', 'insect', 'caterpillars', 'gross', 'disturbing', 'gory', 'gabon', 'graphics', 'greatly', 'sadly', 'somalia', 'hawk', 'managed', 'everybody', 'arnold', 'amphibians', 'mammals', 'novel', 'true', 'upon', 'orange', 'cat', 'frank', 'kitchen', 'meal', 'eats', \"won't\", 'nairobi', 'bucharest', 'standards', \"today's\", 'apparel', 'manufacturer', 'polyester', 'madagascar', 'dark', 'plant', 'association', 'folks', \"i'm\", 'oakland', 'frost', 'chipmunk', 'attempt', 'sad', 'europe', 'slovenia', 'tirana', 'poland', 'polish', 'welfare', 'species', 'pointless', 'dull', 'predictable', 'festival', 'press', 'exploitation', 'villa', 'swam', 'valley', 'cabbage', 'garlic', 'carrots', 'cheese', 'wisconsin', 'zoo', 'rat', \"wouldn't\", 'gauge', 'waste', 'wasted']) \n",
      " \n",
      "\n",
      "dict_keys(['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior', 'grief', '*****', 'pretty', 'error', 'simplest', 'miniature', 'far', 'intellect', 'doodle', 'hanoi', 'an', 'lithuania', 'touches', 'diversion', 'touch', 'negative', 'reviews', 'feedback', 'enough', 'catch', 'screening', 'lucky', '****', '***', 'SPOILER', 'flute', 'mouse', 'rock', 'comments', 'pain', 'loss', 'guilt', 'terms', 'plots', 'query', 'managed', 'acrylic', 'ipod', 'frost', 'vilnius', 'latvia', 'estonia', 'jane', 'folks', 'compound', 'parrot', 'challenge', 'wit', 'chord', 'heart', 'soul', 'terrier', 'golf', 'poodle', 'inconvenient', 'invoice', 'origami', 'damn', 'decent', 'festival', 'press', 'concerned', 'galaxy', 'printer', 'ministry', 'ways', 'pleasant', 'afternoon', 'amusing', 'painting', 'toilet', 'charm', 'dry', 'sharp', 'many', 'cookies', 'industrial', 'magic', '**', 'snowman', 'jack', 'simon', 'scottish', 'scotch', 'infrequently', 'tennis', 'tournament', 'fairly', 'dragonfly', 'tallinn', 'struck', 'cord', 'prejudice', 'dick', 'talking', 'sketch', 'shoulder', 'complicated', 'multiple', 'finished', 'scott', 'producers', 'somehow', 'pull', 'surprise', 'unproductive', 'microwave', 'skirt', 'pet', 'sorry', \"let's\", 'paws', 'cheerfully', 'spent', 'long', 'roll', 'punk', 'band', 'uncertain', 'sheer', 'SPOILERS', 'THIS', 'immunity', 'memphis', 'mate', 'devil', 'welfare', 'implementation', 'quest', 'terror', 'cat', 'clubhouse', 'cartoon', 'shuffle', 'listens', 'husky', 'reference', 'intended', 'suffering', 'ease', 'posted', 'riga', 'international', 'at', 'occasionally', 'implements', 'saturday', 'evening', 'wednesday', 'slovakian', 'suicide', 'timer', 'number', 'forswearing', 'innocence', 'housing', 'ripples', 'pan', 'jazz', 'stockholm', 'truth', 'al', 'calling', 'pyramid', 'sculpture', 'things', 'citrus', 'touched', 'redemption'])\n"
     ]
    }
   ],
   "source": [
    "print(ss1,'\\n','\\n')\n",
    "print(ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inferior not in seeds1\n"
     ]
    }
   ],
   "source": [
    "imdb20_ppmi_so = semantic_orientation(imdb20_n01_ppmi, ss1, ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearsonr's r: 0.186\n",
      "pearsonr's r: 0.026\n",
      "pearsonr's r: 0.169\n"
     ]
    }
   ],
   "source": [
    "evaluation(lexicon, imdb20_ppmi_so, colname='Valence')\n",
    "evaluation(lexicon, imdb20_ppmi_so, colname='Arousal')\n",
    "evaluation(lexicon, imdb20_ppmi_so, colname='Dominance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/morganbryant/Desktop/stanford/CS/v_224u/cs224u'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bake-off submission\n",
    "\n",
    "1. The name of the count matrix you started with (must be one in `vsmdata`).\n",
    "1. The seed-sets you used.\n",
    "1. A description of the steps you took to create your bake-off VSM – must be different from the above baseline.\n",
    "1. Your Pearson r values for 'Valence', 'Arousal', and 'Dominance'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
