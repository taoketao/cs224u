{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bake-off: The semantic orientation method\n",
    "\n",
    "__Important__: This isn't being run as a bake-off this year. It's included in the repository in case people want to do additional exploration or incorporate this kind of evaluation into a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_seeds1 = ('bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior'),\n",
    "default_seeds2 = ('good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior'),\n",
    "\n",
    "def semantic_orientation(\n",
    "        df,        \n",
    "        seeds1=default_seeds1,\n",
    "        seeds2=default_seeds2,\n",
    "        distfunc=vsm.cosine):    \n",
    "    \"\"\"No frills implementation of the semantic Orientation (SO) method of \n",
    "    Turney and Littman. `seeds1` and `seeds2` should be representative members \n",
    "    of two intutively opposing semantic classes. The method will then try \n",
    "    to rank the vocabulary by its relative association with each seed set.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The matrix used to derive the SO ranking.           \n",
    "    seeds1 : tuple of str\n",
    "        The default is the negative seed set of Turney and Littman.        \n",
    "    seeds2 : tuple of str\n",
    "        The default is the positive seed set of Turney and Littman.        \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure \n",
    "        between 1d vectors. \n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    pd.Series\n",
    "        The vocabulary ranked according to the SO method, with words \n",
    "        closest to `seeds1` at the top and words closest to `seeds2` at the \n",
    "        bottom.\n",
    "    \n",
    "    \"\"\"\n",
    "    rownames = set(df.index)\n",
    "    # Check that the seed sets are in the vocabulary, filtering\n",
    "    # where necessary, and warn the user about exclusions:\n",
    "    seeds1 = _value_check(seeds1, \"seeds1\", rownames)\n",
    "    seeds2 = _value_check(seeds2, \"seeds2\", rownames)\n",
    "    \n",
    "    # Subframes for the two seeds-sets\n",
    "    sm1 = df.loc[seeds1]\n",
    "    sm2 = df.loc[seeds2]\n",
    "    \n",
    "    # Core semantic orientation calculation:\n",
    "    def row_func(row):\n",
    "        val1 = sm1.apply(lambda x: distfunc(row, x), axis=1).sum()\n",
    "        val2 = sm2.apply(lambda x: distfunc(row, x), axis=1).sum()\n",
    "        return val1 - val2\n",
    "    \n",
    "    scores = df.apply(row_func, axis=1)\n",
    "    return scores.sort_values(ascending=False)\n",
    "\n",
    "def _value_check(ss, name, rownames):\n",
    "    new = set()\n",
    "    for w in ss:\n",
    "        if w not in rownames:\n",
    "            print(\"Warning: {} not in {}\".format(w, name))\n",
    "        else:\n",
    "            new.add(w)\n",
    "    return new\n",
    "\n",
    "def load_warriner_lexicon(src_filename, df=None):\n",
    "    \"\"\"Read in 'Ratings_Warriner_et_al.csv' and optionally restrict its \n",
    "    vocabulary to items in `df`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to 'Ratings_Warriner_et_al.csv'\n",
    "    df : pd.DataFrame or None\n",
    "        If this is given, then its index is intersected with the \n",
    "        vocabulary from the lexicon, and we return a lexicon \n",
    "        containing only values in both vocabularies.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    lexicon = pd.read_csv(src_filename, index_col=0)\n",
    "    lexicon = lexicon[['Word', 'V.Mean.Sum', 'A.Mean.Sum', 'D.Mean.Sum']]\n",
    "    lexicon = lexicon.set_index('Word').rename(\n",
    "        columns={'V.Mean.Sum': 'Valence', \n",
    "                 'A.Mean.Sum': 'Arousal', \n",
    "                 'D.Mean.Sum': 'Dominance'})\n",
    "    if df is not None:\n",
    "        shared_vocab = sorted(set(lexicon.index) & set(df.index))\n",
    "        lexicon = lexicon.loc[shared_vocab]\n",
    "    return lexicon\n",
    "\n",
    "def evaluation(lexicon, so, colname='Valence', metric=pearsonr):\n",
    "    lexicon['so'] = so\n",
    "    rho, pvalue = metric(lexicon['so'], lexicon[colname])\n",
    "    print(\"{0:}'s r: {1:0.3f}\".format(metric.__name__, rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load data '''\n",
    "this_dir = os.getcwd()\n",
    "data_home = 'vsmdata'\n",
    "imdb20 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window20-flat.csv.gz'), index_col=0)\n",
    "imdb5 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window5-scaled.csv.gz'), index_col=0)\n",
    "print(imdb20.shape, imdb5.shape)\n",
    "# gigaword 5\n",
    "# gigaword 20\n",
    "\n",
    "lexicon = load_warriner_lexicon(\n",
    "    os.path.join(data_home, 'Ratings_Warriner_et_al.csv'),\n",
    "    imdb20) # imdb20 has same shape as imdb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     631.7690\n",
      "     137.9394\n",
      "´     143.6252\n",
      "é     248.1840\n",
      "és    125.9052\n",
      "dtype: float64      631.7690\n",
      "     137.9394\n",
      "´     143.6252\n",
      "é     248.1840\n",
      "és    125.9052\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ABC.apply(vsm.length_norm, axis=1)\n",
    "imdb20_tmp = imdb20.copy()\n",
    "imdb20_tmp.apply(vsm.length_norm, axis=1)\n",
    "\n",
    "#imdb20_tmp.apply(vsm.length_norm, axis=0)\n",
    "#print(imdb20_tmp.mean().tail(), imdb20.mean().tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb20_n0 = imdb20.apply(vsm.length_norm, axis=1)\n",
    "imdb20_n01 = imdb20_n0.apply(vsm.length_norm, axis=0)\n",
    "imdb20_n01_ppmi = vsm.pmi(imdb20_n01)\n",
    "imdb20_n01_ppmi = imdb20_n01_ppmi.apply(vsm.length_norm, axis=1)\n",
    "imdb20_n01_ppmi = imdb20_n01_ppmi.apply(vsm.length_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig set: (('bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior'),)\n",
      "orig ssd: defaultdict(<function bootstrap.<locals>.<lambda> at 0x130110510>, {'bad': 1.0, 'nasty': 1.0, 'poor': 1.0, 'negative': 1.0, 'unfortunate': 1.0, 'wrong': 1.0, 'inferior': 1.0})\n",
      "depth 0 on ['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior'] :\n",
      "current set size: p 0 25\n",
      "depth 1 on ['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior', 'textile', 'worm', 'unpleasant', \"what's\", \"don't\", 'terribly', 'reviews', 'comments', 'positive', 'bratislava', 'excuse', 'liechtenstein', 'scouting', 'events', 'fortunate', 'guys', 'carnivore', 'seed'] :\n",
      "current set size: p 1 69\n",
      "depth 2 on ['bad', 'nasty', 'poor', 'negative', 'unfortunate', 'wrong', 'inferior', 'textile', 'worm', 'unpleasant', \"what's\", \"don't\", 'terribly', 'reviews', 'comments', 'positive', 'bratislava', 'excuse', 'liechtenstein', 'scouting', 'events', 'fortunate', 'guys', 'carnivore', 'seed', 'hole', 'pug', 'giant', 'slovakia', 'warsaw', 'boyfriend', 'simon', 'italian', 'whilst', 'melons', 'talent', 'mammal', 'awesome', 'reptiles', 'dated', 'disappointed', 'boring', 'enough', 'catch', 'screening', 'thoroughly', 'disgusting', 'depressing', 'actual', 'mogadishu', 'based', 'mill', 'fabric', 'garment', 'happening', 'cooking', 'sunflower', 'dandelion', 'onions', 'posted', 'feedback', 'hey', 'dolls', 'milwaukee', 'bother', 'know', 'normally', 'pathetic', 'sorry'] :\n",
      "current set size: p 2 163\n",
      "orig set: (('good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior'),)\n",
      "orig ssd: defaultdict(<function bootstrap.<locals>.<lambda> at 0x130110488>, {'good': 1.0, 'nice': 1.0, 'excellent': 1.0, 'positive': 1.0, 'fortunate': 1.0, 'correct': 1.0, 'superior': 1.0})\n",
      "depth 0 on ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior'] :\n",
      "current set size: n 0 28\n",
      "depth 1 on ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior', 'grief', '*****', 'pretty', 'error', 'simplest', 'miniature', 'far', 'intellect', 'doodle', 'hanoi', 'an', 'lithuania', 'touches', 'diversion', 'touch', 'negative', 'reviews', 'feedback', 'enough', 'catch', 'screening'] :\n",
      "current set size: n 1 76\n",
      "depth 2 on ['good', 'nice', 'excellent', 'positive', 'fortunate', 'correct', 'superior', 'grief', '*****', 'pretty', 'error', 'simplest', 'miniature', 'far', 'intellect', 'doodle', 'hanoi', 'an', 'lithuania', 'touches', 'diversion', 'touch', 'negative', 'reviews', 'feedback', 'enough', 'catch', 'screening', 'lucky', '****', '***', 'SPOILER', 'flute', 'mouse', 'rock', 'comments', 'pain', 'loss', 'guilt', 'terms', 'plots', 'query', 'managed', 'acrylic', 'ipod', 'frost', 'vilnius', 'latvia', 'estonia', 'jane', 'folks', 'compound', 'parrot', 'challenge', 'wit', 'chord', 'heart', 'soul', 'terrier', 'golf', 'poodle', 'inconvenient', 'invoice', 'origami', 'damn', 'decent', 'festival', 'press', 'concerned', 'galaxy', 'printer', 'ministry', 'ways', 'pleasant', 'afternoon', 'amusing'] :\n",
      "current set size: n 2 176\n"
     ]
    }
   ],
   "source": [
    "''' Morgan Bryant: this is a small bootstrapping algorithm\n",
    "that seeks to expand the given default seeds (considered \n",
    "\"paragons\") by operating on a differentially modified dataset.'''\n",
    "\n",
    "import bakeoff_semantic_orientation as bso\n",
    "importlib.reload(bso)\n",
    "\n",
    "# Operate on the seed sets\n",
    "laplace = 1.0\n",
    "nsteps = 3\n",
    "nadditions = 4\n",
    "def dist_factor(step):\n",
    "    return 1.0\n",
    "    #return 1+nsteps-step\n",
    "\n",
    "#DF = imdb20_n01_ppmi\n",
    "df = vsm.pmi(imdb5)\n",
    "ss1_counts, ss1 = bso.bootstrap(default_seeds1, df, 'p', \n",
    "                      dist_factor, laplace, nsteps, nadditions)\n",
    "ss2_counts, ss2 = bso.bootstrap(default_seeds2, df, 'n',\n",
    "                      dist_factor, laplace, nsteps, nadditions)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "176\n",
      "defaultdict(<function <lambda> at 0x10b0a5488>, {'nasty': [4.0, 'n'], 'textile': [4.0, 'n'], 'worm': [4.0, 'n'], 'unpleasant': [4.0, 'n'], 'britain': [4.0, 'n'], 'wrong': [5.0, 'n'], \"what's\": [4.0, 'n'], \"don't\": [4.0, 'n'], 'terribly': [4.0, 'n'], 'ticker': [4.0, 'n'], 'negative': [7.0, 'n'], 'reviews': [7.0, 'n'], 'comments': [6.0, 'n'], 'positive': [6.0, 'n'], 'feedback': [5.0, 'n'], 'poor': [6.0, 'n'], 'bratislava': [4.0, 'n'], 'excuse': [4.0, 'n'], 'liechtenstein': [4.0, 'n'], 'pity': [4.0, 'n'], 'unfortunate': [4.0, 'n'], 'scouting': [4.0, 'n'], 'events': [4.0, 'n'], 'fortunate': [4.0, 'n'], 'circumstances': [4.0, 'n'], 'bad': [3.0, 'n'], 'guys': [4.0, 'n'], 'carnivore': [4.0, 'n'], 'seed': [4.0, 'n'], 'taste': [4.0, 'n'], 'hole': [2.0, 'n'], 'pug': [2.0, 'n'], 'giant': [2.0, 'n'], 'casey': [2.0, 'n'], 'slovakia': [2.0, 'n'], 'warsaw': [2.0, 'n'], 'talk': [2.0, 'n'], 'boyfriend': [2.0, 'n'], 'simon': [2.0, 'n'], 'italian': [2.0, 'n'], 'death': [2.0, 'n'], 'posted': [3.0, 'n'], 'whilst': [2.0, 'n'], 'melons': [2.0, 'n'], 'talent': [2.0, 'n'], 'locations': [2.0, 'n'], 'thats': [2.0, 'n'], 'keeps': [2.0, 'n'], 'strange': [2.0, 'n'], 'feeding': [2.0, 'n'], 'mammal': [2.0, 'n'], 'awesome': [2.0, 'n'], 'reptiles': [2.0, 'n'], 'conservation': [2.0, 'n'], 'dated': [2.0, 'n'], 'disappointed': [2.0, 'n'], 'boring': [2.0, 'n'], 'thoroughly': [2.0, 'n'], 'disgusting': [2.0, 'n'], 'depressing': [2.0, 'n'], 'france': [2.0, 'n'], 'battle': [2.0, 'n'], 'belize': [2.0, 'n'], 'ireland': [2.0, 'n'], 'actual': [2.0, 'n'], 'mogadishu': [2.0, 'n'], 'based': [2.0, 'n'], 'under': [2.0, 'n'], 'normal': [2.0, 'n'], 'extraordinary': [2.0, 'n'], 'mysterious': [2.0, 'n'], 'mill': [2.0, 'n'], 'fabric': [2.0, 'n'], 'garment': [2.0, 'n'], 'cemetery': [2.0, 'n'], 'instrument': [2.0, 'n'], 'immunity': [2.0, 'n'], \"it's\": [2.0, 'n'], 'happening': [2.0, 'n'], 'cooking': [2.0, 'n'], 'eating': [2.0, 'n'], 'sunflower': [2.0, 'n'], 'dandelion': [2.0, 'n'], 'onions': [2.0, 'n'], 'plant': [2.0, 'n'], 'reading': [2.0, 'n'], 'hey': [2.0, 'n'], 'dolls': [2.0, 'n'], 'milwaukee': [2.0, 'n'], 'smartest': [2.0, 'n'], 'bother': [2.0, 'n'], 'know': [2.0, 'n'], 'normally': [2.0, 'n'], 'listen': [2.0, 'n'], 'hearing': [2.0, 'n'], 'pathetic': [2.0, 'n'], 'sorry': [2.0, 'n'], 'please': [2.0, 'n'], 'mouth': [2.0, 'n'], 'buds': [2.0, 'n'], 'bitter': [2.0, 'n'], 'smell': [2.0, 'n'], 'enough': [2.0, 'n'], 'catch': [2.0, 'n'], 'screening': [2.0, 'n'], 'tickets': [2.0, 'n']})\n"
     ]
    }
   ],
   "source": [
    "print(len(ss1))\n",
    "print(len(ss2))\n",
    "print(ssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inferior not in seeds1\n"
     ]
    }
   ],
   "source": [
    "imdb20_ppmi_so = semantic_orientation(imdb20_n01_ppmi, ss1, ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearsonr's r: 0.385\n",
      "pearsonr's r: 0.004\n",
      "pearsonr's r: 0.340\n"
     ]
    }
   ],
   "source": [
    "evaluation(lexicon, imdb20_ppmi_so, colname='Valence')\n",
    "evaluation(lexicon, imdb20_ppmi_so, colname='Arousal')\n",
    "evaluation(lexicon, imdb20_ppmi_so, colname='Dominance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/morganbryant/Desktop/stanford/CS/v_224u/cs224u'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bake-off submission\n",
    "\n",
    "1. The name of the count matrix you started with (must be one in `vsmdata`).\n",
    "1. The seed-sets you used.\n",
    "1. A description of the steps you took to create your bake-off VSM – must be different from the above baseline.\n",
    "1. Your Pearson r values for 'Valence', 'Arousal', and 'Dominance'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
